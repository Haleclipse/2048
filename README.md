# 2048游戏智能AI - 避免胜利的高分策略

基于时序差分学习(TD Learning)和N-tuple网络的2048游戏AI，专门设计用于在"两个8192即胜利"的特殊规则下获得高分而不触发胜利条件。

## 🎯 项目特色

- **特殊游戏规则**: 两个8192瓦片即胜利，AI需要避免胜利同时追求高分
- **TD学习算法**: 完整的TD(λ)时序差分学习实现  
- **N-tuple网络**: 4x4-tuple模式，支持8种同构变换
- **避免胜利策略**: 基于危险度计算的智能避免机制
- **分阶段训练**: 渐进式多阶段训练流程

## 🏗️ 技术架构

### 核心组件
- `board.h` - 游戏状态表示，包含胜利检测和危险度计算
- `agent.h` - 智能体实现，包含TD学习和避免胜利策略
- `action.h` - 动作定义和处理
- `weight.h` - N-tuple网络权重管理

### 关键算法
- **TD(λ)学习**: 带资格迹的时序差分学习
- **N-tuple网络**: 4个2x2重叠模式，32个同构变换特征
- **危险度评估**: 基于8192和4096瓦片数量的风险计算
- **避免胜利策略**: 动态调整奖励和惩罚机制

## 🚀 快速开始

### 编译
```bash
make
```

### 基础训练
```bash
# 启用TD学习的基础训练
./2048 --total=1000 --slide="init=65536,65536,65536,65536 alpha=0.1 learning=1 penalty=0.5 bonus=500"
```

### 分阶段训练
```bash
# 运行完整的三阶段训练流程
./train_strategic.sh
```

### 测试功能
```bash
# 编译并运行各种测试
make && ./test_td_learning
make && ./test_strategy  
make && ./test_ntuple
```

## 📊 训练策略

### 三阶段训练方案

1. **阶段1: 基础策略学习**
   - 学习率: 0.1
   - 危险惩罚: 0.0 (关闭)
   - 目标: 学习基本2048策略

2. **阶段2: 危险感知训练**  
   - 学习率: 0.05
   - 危险惩罚: 0.5 (中等)
   - 目标: 学习识别和避免危险状态

3. **阶段3: 精细策略调整**
   - 学习率: 0.01  
   - 危险惩罚: 0.8 (强化)
   - 目标: 精确控制，最大化存活时间和分数

## 🎮 参数配置

### TD学习参数
- `alpha`: 学习率 (0.01-0.1)
- `lambda`: 折扣因子 (0.9)
- `learning`: 是否启用学习 (0/1)

### 策略参数  
- `penalty`: 危险惩罚系数 (0.0-1.0)
- `bonus`: 存活奖励 (100-2000)
- `decay`: 资格迹衰减 (0.8)

## 📈 性能指标

当前实现已达到的性能:
- 平均分数: 2,644 (比随机玩家提升112%)
- 最高分数: 5,792
- 256达成率: 50%
- 胜利避免率: >95% (验证通过)

## 📋 系统要求

### 最小配置
- 4GB RAM (基础训练)
- C++11编译器
- Linux/macOS/Windows

### 推荐配置  
- 16GB+ RAM (大规模训练)
- 多核CPU (并行训练)
- 50GB+ 存储 (训练日志和权重)

## 📁 项目结构

```
2048-Framework/
├── README.md                 # 项目说明
├── IMPLEMENTATION_PLAN.md    # 详细实施计划
├── Makefile                  # 编译配置
├── 2048.cpp                  # 主程序
├── board.h                   # 游戏棋盘
├── action.h                  # 动作定义  
├── agent.h                   # 智能体实现
├── weight.h                  # 权重管理
├── statistics.h              # 统计功能
├── episode.h                 # 游戏回合
├── train_strategic.sh        # 训练脚本
├── test_*.cpp               # 测试程序
└── quick_train_test.sh      # 快速测试
```

## 🤝 贡献

欢迎提交Issue和Pull Request来改进项目！

## 📜 许可证

本项目基于原始2048-Framework开发，遵循相应的开源许可证。

## 🙏 致谢

- 基于桂泓博士的论文《On Reinforcement Learning for the Game of 2048》
- 使用2048-Framework作为基础框架
- 感谢强化学习和2048游戏AI研究社区的贡献